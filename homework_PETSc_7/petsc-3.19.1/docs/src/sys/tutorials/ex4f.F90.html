<center><a href="https://gitlab.com/petsc/petsc/-/blob/a093114c2e7b4ba1f47e6ac8a72c57724150f16d/src/sys/tutorials/ex4f.F90">Actual source code: ex4f.F90</a></center><br>

<html>
<head>
<title></title>
<meta name="generator" content="c2html 0.9.4">
<meta name="date" content="2023-04-30T14:19:57+00:00">
</head>

<body bgcolor="#FFFFFF">
<pre width="80">
<a name="line1">  1: </a>!
<a name="line2">  2: </a>!     This introductory example illustrates running PETSc on a subset
<a name="line3">  3: </a>!     of processes
<a name="line4">  4: </a>!
<a name="line5">  5: </a>! -----------------------------------------------------------------------

<a name="line7">  7: </a>      program main
<a name="line8">  8: </a>#include <A href="../../../include/petsc/finclude/petscsys.h.html">&lt;petsc/finclude/petscsys.h&gt;</A>
<a name="line9">  9: </a>      use petscmpi  ! or mpi or mpi_f08
<a name="line10"> 10: </a>      use petscsys
<a name="line11"> 11: </a>      implicit none
<a name="line12"> 12: </a>      <a href="../../../manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> ierr
<a name="line13"> 13: </a>      <a href="../../../manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>    rank, size,grank,zero,two
<a name="line14"> 14: </a>      <a href="../../../manualpages/Sys/PetscReal.html">PetscReal</a> globalrank

<a name="line16"> 16: </a>!     We must call <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Init.html#MPI_Init">MPI_Init</a>() first, making us, not PETSc, responsible <font color="#4169E1">for</font> MPI

<a name="line18"> 18: </a>      PetscCallMPIA(<a href="http://www.mpich.org/static/docs/latest/www3/MPI_Init.html#MPI_Init">MPI_Init</a>(ierr))
<a name="line19"> 19: </a><font color="#A020F0">#if defined(PETSC_HAVE_ELEMENTAL)</font>
<a name="line20"> 20: </a>      <a href="../../../manualpages/Sys/PetscCallA.html">PetscCallA</a>(<a href="../../../manualpages/Sys/PetscElementalInitializePackage.html">PetscElementalInitializePackage</a>(ierr))
<a name="line21"> 21: </a><font color="#A020F0">#endif</font>
<a name="line22"> 22: </a>!     We can now change the communicator universe <font color="#4169E1">for</font> PETSc

<a name="line24"> 24: </a>      zero = 0
<a name="line25"> 25: </a>      two = 2
<a name="line26"> 26: </a>      PetscCallMPIA(<a href="http://www.mpich.org/static/docs/latest/www3/MPI_Comm_rank.html#MPI_Comm_rank">MPI_Comm_rank</a>(MPI_COMM_WORLD,rank,ierr))
<a name="line27"> 27: </a>      PetscCallMPIA(<a href="http://www.mpich.org/static/docs/latest/www3/MPI_Comm_split.html#MPI_Comm_split">MPI_Comm_split</a>(MPI_COMM_WORLD,mod(rank,two),zero,<a href="../../../manualpages/Sys/PETSC_COMM_WORLD.html">PETSC_COMM_WORLD</a>,ierr))

<a name="line29"> 29: </a>!     Every PETSc routine should begin with the <a href="../../../manualpages/Sys/PetscInitialize.html">PetscInitialize</a>()
<a name="line30"> 30: </a>!     routine.
<a name="line31"> 31: </a>      <a href="../../../manualpages/Sys/PetscCallA.html">PetscCallA</a>(<a href="../../../manualpages/Sys/PetscInitializeNoArguments.html">PetscInitializeNoArguments</a>(ierr))

<a name="line33"> 33: </a>!     The following MPI calls <font color="#4169E1">return</font> the number of processes being used
<a name="line34"> 34: </a>!     and the rank of this process in the group.

<a name="line36"> 36: </a>      PetscCallMPIA(<a href="http://www.mpich.org/static/docs/latest/www3/MPI_Comm_size.html#MPI_Comm_size">MPI_Comm_size</a>(<a href="../../../manualpages/Sys/PETSC_COMM_WORLD.html">PETSC_COMM_WORLD</a>,size,ierr))
<a name="line37"> 37: </a>      PetscCallMPIA(<a href="http://www.mpich.org/static/docs/latest/www3/MPI_Comm_rank.html#MPI_Comm_rank">MPI_Comm_rank</a>(<a href="../../../manualpages/Sys/PETSC_COMM_WORLD.html">PETSC_COMM_WORLD</a>,rank,ierr))

<a name="line39"> 39: </a>!     Here we would like to print only one message that represents all
<a name="line40"> 40: </a>!     the processes in the group. Sleep so that IO from different ranks
<a name="line41"> 41: </a>!     don't get mixed up. Note this is not an ideal solution
<a name="line42"> 42: </a>      PetscCallMPIA(<a href="http://www.mpich.org/static/docs/latest/www3/MPI_Comm_rank.html#MPI_Comm_rank">MPI_Comm_rank</a>(MPI_COMM_WORLD,grank,ierr))
<a name="line43"> 43: </a>      globalrank = grank
<a name="line44"> 44: </a>      <a href="../../../manualpages/Sys/PetscCallA.html">PetscCallA</a>(<a href="../../../manualpages/Sys/PetscSleep.html">PetscSleep</a>(globalrank,ierr))
<a name="line45"> 45: </a>      <font color="#4169E1">if</font> (rank .eq. 0) write(6,100) size,rank
<a name="line46"> 46: </a> 100  format('No of Procs = ',i4,' rank = ',i4)

<a name="line48"> 48: </a>!     Always call <a href="../../../manualpages/Sys/PetscFinalize.html">PetscFinalize</a>() before exiting a program.  This
<a name="line49"> 49: </a>!     routine - finalizes the PETSc libraries as well as MPI - provides
<a name="line50"> 50: </a>!     summary and diagnostic information <font color="#4169E1">if</font> certain runtime options are
<a name="line51"> 51: </a>!     chosen (e.g., -log_view).  See <a href="../../../manualpages/Sys/PetscFinalize.html">PetscFinalize</a>() manpage <font color="#4169E1">for</font> more
<a name="line52"> 52: </a>!     information.

<a name="line54"> 54: </a>      <a href="../../../manualpages/Sys/PetscCallA.html">PetscCallA</a>(<a href="../../../manualpages/Sys/PetscFinalize.html">PetscFinalize</a>(ierr))
<a name="line55"> 55: </a>      PetscCallMPIA(<a href="http://www.mpich.org/static/docs/latest/www3/MPI_Comm_free.html#MPI_Comm_free">MPI_Comm_free</a>(<a href="../../../manualpages/Sys/PETSC_COMM_WORLD.html">PETSC_COMM_WORLD</a>,ierr))
<a name="line56"> 56: </a><font color="#A020F0">#if defined(PETSC_HAVE_ELEMENTAL)</font>
<a name="line57"> 57: </a>      <a href="../../../manualpages/Sys/PetscCallA.html">PetscCallA</a>(<a href="../../../manualpages/Sys/PetscElementalFinalizePackage.html">PetscElementalFinalizePackage</a>(ierr))
<a name="line58"> 58: </a><font color="#A020F0">#endif</font>

<a name="line60"> 60: </a>!     Since we initialized MPI, we must call <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Finalize.html#MPI_Finalize">MPI_Finalize</a>()

<a name="line62"> 62: </a>      PetscCallMPIA(<a href="http://www.mpich.org/static/docs/latest/www3/MPI_Finalize.html#MPI_Finalize">MPI_Finalize</a>(ierr))
<a name="line63"> 63: </a>      end

<a name="line65"> 65: </a>!<font color="#B22222">/*TEST</font>
<a name="line66"> 66: </a><font color="#B22222">!</font>
<a name="line67"> 67: </a><font color="#B22222">!   test:</font>
<a name="line68"> 68: </a><font color="#B22222">!      nsize: 5</font>
<a name="line69"> 69: </a><font color="#B22222">!      filter: sort -b</font>
<a name="line70"> 70: </a><font color="#B22222">!      filter_output: sort -b</font>
<a name="line71"> 71: </a><font color="#B22222">!      requires: !cuda !saws</font>
<a name="line72"> 72: </a><font color="#B22222">!</font>
<a name="line73"> 73: </a><font color="#B22222">!TEST*/</font>
</pre>
</body>

</html>
