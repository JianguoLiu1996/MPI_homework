:orphan:
# DMDAGetProcessorSubsets
Returns communicators consisting only of the processors in a `DMDA` adjacent in a particular dimension, corresponding to a logical plane in a 3D grid or a line in a 2D grid. 
## Synopsis
```
#include "petscdmda.h"   
PetscErrorCode DMDAGetProcessorSubsets(DM da, DMDirection dir, MPI_Comm *subcomm)
```
Collective; No Fortran Support


## Input Parameters

- ***da -*** the distributed array
- ***dir -*** Cartesian direction, either `DM_X`, `DM_Y`, or `DM_Z`



## Output Parameter

- ***subcomm -*** new communicator





## Notes
This routine is useful for distributing one-dimensional data in a tensor product grid.

After use, comm should be freed with `MPI_Comm_free()`


## See Also
 `DM`, `DMDA`, `DMDirection`

## Level
advanced

## Location
<A HREF="PETSC_DOC_OUT_ROOT_PLACEHOLDER/src/dm/impls/da/dasub.c.html#DMDAGetProcessorSubsets">src/dm/impls/da/dasub.c</A>

## Examples
<A HREF="PETSC_DOC_OUT_ROOT_PLACEHOLDER/src/dm/tutorials/ex51.c.html">src/dm/tutorials/ex51.c</A><BR>


---
[Edit on GitLab](https://gitlab.com/petsc/petsc/-/edit/release/src/dm/impls/da/dasub.c)


[Index of all DMDA routines](index.md)  
[Table of Contents for all manual pages](/manualpages/index.md)  
[Index of all manual pages](/manualpages/singleindex.md)  
